// Code generated by cue get go. DO NOT EDIT.

//cue:generate cue get go github.com/upbound/provider-gcp/apis/container/v1beta1

package v1beta1

import (
	"github.com/crossplane/crossplane-runtime/apis/common/v1"
	metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
)

#NodeConfigGuestAcceleratorGpuDriverInstallationConfigInitParameters: {
	// The Kubernetes version for the nodes in this pool. Note that if this field
	// and auto_upgrade are both specified, they will fight each other for what the node version should
	// be, so setting both is highly discouraged.
	gpuDriverVersion?: null | string @go(GpuDriverVersion,*string)
}

#NodeConfigGuestAcceleratorGpuDriverInstallationConfigObservation: {
	// The Kubernetes version for the nodes in this pool. Note that if this field
	// and auto_upgrade are both specified, they will fight each other for what the node version should
	// be, so setting both is highly discouraged.
	gpuDriverVersion?: null | string @go(GpuDriverVersion,*string)
}

#NodeConfigGuestAcceleratorGpuDriverInstallationConfigParameters: {
	// The Kubernetes version for the nodes in this pool. Note that if this field
	// and auto_upgrade are both specified, they will fight each other for what the node version should
	// be, so setting both is highly discouraged.
	// +kubebuilder:validation:Optional
	gpuDriverVersion?: null | string @go(GpuDriverVersion,*string)
}

#NodeConfigGuestAcceleratorGpuSharingConfigInitParameters: {
	gpuSharingStrategy?:     null | string  @go(GpuSharingStrategy,*string)
	maxSharedClientsPerGpu?: null | float64 @go(MaxSharedClientsPerGpu,*float64)
}

#NodeConfigGuestAcceleratorGpuSharingConfigObservation: {
	gpuSharingStrategy?:     null | string  @go(GpuSharingStrategy,*string)
	maxSharedClientsPerGpu?: null | float64 @go(MaxSharedClientsPerGpu,*float64)
}

#NodeConfigGuestAcceleratorGpuSharingConfigParameters: {
	// +kubebuilder:validation:Optional
	gpuSharingStrategy?: null | string @go(GpuSharingStrategy,*string)

	// +kubebuilder:validation:Optional
	maxSharedClientsPerGpu?: null | float64 @go(MaxSharedClientsPerGpu,*float64)
}

#NodeConfigSoleTenantConfigNodeAffinityInitParameters: {
	key?:      null | string @go(Key,*string)
	operator?: null | string @go(Operator,*string)
	values?: [...null | string] @go(Values,[]*string)
}

#NodeConfigSoleTenantConfigNodeAffinityObservation: {
	key?:      null | string @go(Key,*string)
	operator?: null | string @go(Operator,*string)
	values?: [...null | string] @go(Values,[]*string)
}

#NodeConfigSoleTenantConfigNodeAffinityParameters: {
	// +kubebuilder:validation:Optional
	key?: null | string @go(Key,*string)

	// +kubebuilder:validation:Optional
	operator?: null | string @go(Operator,*string)

	// +kubebuilder:validation:Optional
	values: [...null | string] @go(Values,[]*string)
}

#NodePoolAutoscalingInitParameters: {
	// Location policy specifies the algorithm used when
	// scaling-up the node pool. Location policy is supported only in 1.24.1+ clusters.
	locationPolicy?: null | string @go(LocationPolicy,*string)

	// Maximum number of nodes per zone in the NodePool.
	// Must be >= min_node_count. Cannot be used with total limits.
	maxNodeCount?: null | float64 @go(MaxNodeCount,*float64)

	// Minimum number of nodes per zone in the NodePool.
	// Must be >=0 and <= max_node_count. Cannot be used with total limits.
	minNodeCount?: null | float64 @go(MinNodeCount,*float64)

	// Total maximum number of nodes in the NodePool.
	// Must be >= total_min_node_count. Cannot be used with per zone limits.
	// Total size limits are supported only in 1.24.1+ clusters.
	totalMaxNodeCount?: null | float64 @go(TotalMaxNodeCount,*float64)

	// Total minimum number of nodes in the NodePool.
	// Must be >=0 and <= total_max_node_count. Cannot be used with per zone limits.
	// Total size limits are supported only in 1.24.1+ clusters.
	totalMinNodeCount?: null | float64 @go(TotalMinNodeCount,*float64)
}

#NodePoolAutoscalingObservation: {
	// Location policy specifies the algorithm used when
	// scaling-up the node pool. Location policy is supported only in 1.24.1+ clusters.
	locationPolicy?: null | string @go(LocationPolicy,*string)

	// Maximum number of nodes per zone in the NodePool.
	// Must be >= min_node_count. Cannot be used with total limits.
	maxNodeCount?: null | float64 @go(MaxNodeCount,*float64)

	// Minimum number of nodes per zone in the NodePool.
	// Must be >=0 and <= max_node_count. Cannot be used with total limits.
	minNodeCount?: null | float64 @go(MinNodeCount,*float64)

	// Total maximum number of nodes in the NodePool.
	// Must be >= total_min_node_count. Cannot be used with per zone limits.
	// Total size limits are supported only in 1.24.1+ clusters.
	totalMaxNodeCount?: null | float64 @go(TotalMaxNodeCount,*float64)

	// Total minimum number of nodes in the NodePool.
	// Must be >=0 and <= total_max_node_count. Cannot be used with per zone limits.
	// Total size limits are supported only in 1.24.1+ clusters.
	totalMinNodeCount?: null | float64 @go(TotalMinNodeCount,*float64)
}

#NodePoolAutoscalingParameters: {
	// Location policy specifies the algorithm used when
	// scaling-up the node pool. Location policy is supported only in 1.24.1+ clusters.
	// +kubebuilder:validation:Optional
	locationPolicy?: null | string @go(LocationPolicy,*string)

	// Maximum number of nodes per zone in the NodePool.
	// Must be >= min_node_count. Cannot be used with total limits.
	// +kubebuilder:validation:Optional
	maxNodeCount?: null | float64 @go(MaxNodeCount,*float64)

	// Minimum number of nodes per zone in the NodePool.
	// Must be >=0 and <= max_node_count. Cannot be used with total limits.
	// +kubebuilder:validation:Optional
	minNodeCount?: null | float64 @go(MinNodeCount,*float64)

	// Total maximum number of nodes in the NodePool.
	// Must be >= total_min_node_count. Cannot be used with per zone limits.
	// Total size limits are supported only in 1.24.1+ clusters.
	// +kubebuilder:validation:Optional
	totalMaxNodeCount?: null | float64 @go(TotalMaxNodeCount,*float64)

	// Total minimum number of nodes in the NodePool.
	// Must be >=0 and <= total_max_node_count. Cannot be used with per zone limits.
	// Total size limits are supported only in 1.24.1+ clusters.
	// +kubebuilder:validation:Optional
	totalMinNodeCount?: null | float64 @go(TotalMinNodeCount,*float64)
}

#NodePoolInitParameters_2: {
	// Configuration required by cluster autoscaler to adjust
	// the size of the node pool to the current cluster usage. Structure is documented below.
	autoscaling?: [...#NodePoolAutoscalingInitParameters] @go(Autoscaling,[]NodePoolAutoscalingInitParameters)

	// The initial number of nodes for the pool. In
	// regional or multi-zonal clusters, this is the number of nodes per zone. Changing
	// this will force recreation of the resource.  If you don't
	// need this value, don't set it.  If you do need it, you can use a lifecycle block to
	// ignore subsequent changes to this field.
	initialNodeCount?: null | float64 @go(InitialNodeCount,*float64)

	// Node management configuration, wherein auto-repair and
	// auto-upgrade is configured. Structure is documented below.
	management?: [...#NodePoolManagementInitParameters_2] @go(Management,[]NodePoolManagementInitParameters_2)

	// The maximum number of pods per node in this node pool.
	// Note that this does not work on node pools which are "route-based" - that is, node
	// pools belonging to clusters that do not have IP Aliasing enabled.
	// See the official documentation
	// for more information.
	maxPodsPerNode?: null | float64 @go(MaxPodsPerNode,*float64)

	// The network configuration of the pool. Such as
	// configuration for Adding Pod IP address ranges) to the node pool. Or enabling private nodes. Structure is
	// documented below
	networkConfig?: [...#NodePoolNetworkConfigInitParameters] @go(NetworkConfig,[]NodePoolNetworkConfigInitParameters)

	// Parameters used in creating the node pool. See
	// google_container_cluster for schema.
	nodeConfig?: [...#NodePoolNodeConfigInitParameters_2] @go(NodeConfig,[]NodePoolNodeConfigInitParameters_2)

	// The number of nodes per instance group. This field can be used to
	// update the number of nodes per instance group but should not be used alongside autoscaling.
	nodeCount?: null | float64 @go(NodeCount,*float64)

	// The list of zones in which the node pool's nodes should be located. Nodes must
	// be in the region of their regional cluster or in the same region as their
	// cluster's zone for zonal clusters. If unspecified, the cluster-level
	// node_locations will be used.
	nodeLocations?: [...null | string] @go(NodeLocations,[]*string)

	// Specifies a custom placement policy for the
	// nodes.
	placementPolicy?: [...#NodePoolPlacementPolicyInitParameters] @go(PlacementPolicy,[]NodePoolPlacementPolicyInitParameters)

	// The ID of the project in which to create the node pool. If blank,
	// the provider-configured project will be used.
	project?: null | string @go(Project,*string)

	// Specify node upgrade settings to change how GKE upgrades nodes.
	// The maximum number of nodes upgraded simultaneously is limited to 20. Structure is documented below.
	upgradeSettings?: [...#NodePoolUpgradeSettingsInitParameters_2] @go(UpgradeSettings,[]NodePoolUpgradeSettingsInitParameters_2)

	// The Kubernetes version for the nodes in this pool. Note that if this field
	// and auto_upgrade are both specified, they will fight each other for what the node version should
	// be, so setting both is highly discouraged.
	version?: null | string @go(Version,*string)
}

#NodePoolManagementInitParameters_2: {
	// Whether the nodes will be automatically repaired.
	autoRepair?: null | bool @go(AutoRepair,*bool)

	// Whether the nodes will be automatically upgraded.
	autoUpgrade?: null | bool @go(AutoUpgrade,*bool)
}

#NodePoolManagementObservation_2: {
	// Whether the nodes will be automatically repaired.
	autoRepair?: null | bool @go(AutoRepair,*bool)

	// Whether the nodes will be automatically upgraded.
	autoUpgrade?: null | bool @go(AutoUpgrade,*bool)
}

#NodePoolManagementParameters_2: {
	// Whether the nodes will be automatically repaired.
	// +kubebuilder:validation:Optional
	autoRepair?: null | bool @go(AutoRepair,*bool)

	// Whether the nodes will be automatically upgraded.
	// +kubebuilder:validation:Optional
	autoUpgrade?: null | bool @go(AutoUpgrade,*bool)
}

#NodePoolNetworkConfigInitParameters: {
	// Whether to create a new range for pod IPs in this node pool. Defaults are provided for pod_range and pod_ipv4_cidr_block if they are not specified.
	createPodRange?: null | bool @go(CreatePodRange,*bool)

	// Whether nodes have internal IP addresses only.
	enablePrivateNodes?: null | bool @go(EnablePrivateNodes,*bool)
	podCidrOverprovisionConfig?: [...#NodePoolNetworkConfigPodCidrOverprovisionConfigInitParameters] @go(PodCidrOverprovisionConfig,[]NodePoolNetworkConfigPodCidrOverprovisionConfigInitParameters)

	// The IP address range for pod IPs in this node pool. Only applicable if createPodRange is true. Set to blank to have a range chosen with the default size. Set to /netmask (e.g. /14) to have a range chosen with a specific netmask. Set to a CIDR notation (e.g. 10.96.0.0/14) to pick a specific range to use.
	podIpv4CidrBlock?: null | string @go(PodIPv4CidrBlock,*string)

	// The ID of the secondary range for pod IPs. If create_pod_range is true, this ID is used for the new range. If create_pod_range is false, uses an existing secondary range with this ID.
	podRange?: null | string @go(PodRange,*string)
}

#NodePoolNetworkConfigObservation: {
	// Whether to create a new range for pod IPs in this node pool. Defaults are provided for pod_range and pod_ipv4_cidr_block if they are not specified.
	createPodRange?: null | bool @go(CreatePodRange,*bool)

	// Whether nodes have internal IP addresses only.
	enablePrivateNodes?: null | bool @go(EnablePrivateNodes,*bool)
	podCidrOverprovisionConfig?: [...#NodePoolNetworkConfigPodCidrOverprovisionConfigObservation] @go(PodCidrOverprovisionConfig,[]NodePoolNetworkConfigPodCidrOverprovisionConfigObservation)

	// The IP address range for pod IPs in this node pool. Only applicable if createPodRange is true. Set to blank to have a range chosen with the default size. Set to /netmask (e.g. /14) to have a range chosen with a specific netmask. Set to a CIDR notation (e.g. 10.96.0.0/14) to pick a specific range to use.
	podIpv4CidrBlock?: null | string @go(PodIPv4CidrBlock,*string)

	// The ID of the secondary range for pod IPs. If create_pod_range is true, this ID is used for the new range. If create_pod_range is false, uses an existing secondary range with this ID.
	podRange?: null | string @go(PodRange,*string)
}

#NodePoolNetworkConfigParameters: {
	// Whether to create a new range for pod IPs in this node pool. Defaults are provided for pod_range and pod_ipv4_cidr_block if they are not specified.
	// +kubebuilder:validation:Optional
	createPodRange?: null | bool @go(CreatePodRange,*bool)

	// Whether nodes have internal IP addresses only.
	// +kubebuilder:validation:Optional
	enablePrivateNodes?: null | bool @go(EnablePrivateNodes,*bool)

	// +kubebuilder:validation:Optional
	podCidrOverprovisionConfig?: [...#NodePoolNetworkConfigPodCidrOverprovisionConfigParameters] @go(PodCidrOverprovisionConfig,[]NodePoolNetworkConfigPodCidrOverprovisionConfigParameters)

	// The IP address range for pod IPs in this node pool. Only applicable if createPodRange is true. Set to blank to have a range chosen with the default size. Set to /netmask (e.g. /14) to have a range chosen with a specific netmask. Set to a CIDR notation (e.g. 10.96.0.0/14) to pick a specific range to use.
	// +kubebuilder:validation:Optional
	podIpv4CidrBlock?: null | string @go(PodIPv4CidrBlock,*string)

	// The ID of the secondary range for pod IPs. If create_pod_range is true, this ID is used for the new range. If create_pod_range is false, uses an existing secondary range with this ID.
	// +kubebuilder:validation:Optional
	podRange?: null | string @go(PodRange,*string)
}

#NodePoolNetworkConfigPodCidrOverprovisionConfigInitParameters: {
	disabled?: null | bool @go(Disabled,*bool)
}

#NodePoolNetworkConfigPodCidrOverprovisionConfigObservation: {
	disabled?: null | bool @go(Disabled,*bool)
}

#NodePoolNetworkConfigPodCidrOverprovisionConfigParameters: {
	// +kubebuilder:validation:Optional
	disabled?: null | bool @go(Disabled,*bool)
}

#NodePoolNodeConfigAdvancedMachineFeaturesInitParameters: {
	threadsPerCore?: null | float64 @go(ThreadsPerCore,*float64)
}

#NodePoolNodeConfigAdvancedMachineFeaturesObservation: {
	threadsPerCore?: null | float64 @go(ThreadsPerCore,*float64)
}

#NodePoolNodeConfigAdvancedMachineFeaturesParameters: {
	// +kubebuilder:validation:Optional
	threadsPerCore?: null | float64 @go(ThreadsPerCore,*float64)
}

#NodePoolNodeConfigEphemeralStorageLocalSsdConfigInitParameters: {
	localSsdCount?: null | float64 @go(LocalSsdCount,*float64)
}

#NodePoolNodeConfigEphemeralStorageLocalSsdConfigObservation: {
	localSsdCount?: null | float64 @go(LocalSsdCount,*float64)
}

#NodePoolNodeConfigEphemeralStorageLocalSsdConfigParameters: {
	// +kubebuilder:validation:Optional
	localSsdCount?: null | float64 @go(LocalSsdCount,*float64)
}

#NodePoolNodeConfigGcfsConfigInitParameters: {
	enabled?: null | bool @go(Enabled,*bool)
}

#NodePoolNodeConfigGcfsConfigObservation: {
	enabled?: null | bool @go(Enabled,*bool)
}

#NodePoolNodeConfigGcfsConfigParameters: {
	// +kubebuilder:validation:Optional
	enabled?: null | bool @go(Enabled,*bool)
}

#NodePoolNodeConfigGuestAcceleratorInitParameters: {
	count?: null | float64 @go(Count,*float64)
	gpuDriverInstallationConfig?: [...#NodeConfigGuestAcceleratorGpuDriverInstallationConfigInitParameters] @go(GpuDriverInstallationConfig,[]NodeConfigGuestAcceleratorGpuDriverInstallationConfigInitParameters)
	gpuPartitionSize?: null | string @go(GpuPartitionSize,*string)
	gpuSharingConfig?: [...#NodeConfigGuestAcceleratorGpuSharingConfigInitParameters] @go(GpuSharingConfig,[]NodeConfigGuestAcceleratorGpuSharingConfigInitParameters)

	// The type of the policy. Supports a single value: COMPACT.
	// Specifying COMPACT placement policy type places node pool's nodes in a closer
	// physical proximity in order to reduce network latency between nodes.
	type?: null | string @go(Type,*string)
}

#NodePoolNodeConfigGuestAcceleratorObservation: {
	count?: null | float64 @go(Count,*float64)
	gpuDriverInstallationConfig?: [...#NodeConfigGuestAcceleratorGpuDriverInstallationConfigObservation] @go(GpuDriverInstallationConfig,[]NodeConfigGuestAcceleratorGpuDriverInstallationConfigObservation)
	gpuPartitionSize?: null | string @go(GpuPartitionSize,*string)
	gpuSharingConfig?: [...#NodeConfigGuestAcceleratorGpuSharingConfigObservation] @go(GpuSharingConfig,[]NodeConfigGuestAcceleratorGpuSharingConfigObservation)

	// The type of the policy. Supports a single value: COMPACT.
	// Specifying COMPACT placement policy type places node pool's nodes in a closer
	// physical proximity in order to reduce network latency between nodes.
	type?: null | string @go(Type,*string)
}

#NodePoolNodeConfigGuestAcceleratorParameters: {
	// +kubebuilder:validation:Optional
	count?: null | float64 @go(Count,*float64)

	// +kubebuilder:validation:Optional
	gpuDriverInstallationConfig?: [...#NodeConfigGuestAcceleratorGpuDriverInstallationConfigParameters] @go(GpuDriverInstallationConfig,[]NodeConfigGuestAcceleratorGpuDriverInstallationConfigParameters)

	// +kubebuilder:validation:Optional
	gpuPartitionSize?: null | string @go(GpuPartitionSize,*string)

	// +kubebuilder:validation:Optional
	gpuSharingConfig?: [...#NodeConfigGuestAcceleratorGpuSharingConfigParameters] @go(GpuSharingConfig,[]NodeConfigGuestAcceleratorGpuSharingConfigParameters)

	// The type of the policy. Supports a single value: COMPACT.
	// Specifying COMPACT placement policy type places node pool's nodes in a closer
	// physical proximity in order to reduce network latency between nodes.
	// +kubebuilder:validation:Optional
	type?: null | string @go(Type,*string)
}

#NodePoolNodeConfigGvnicInitParameters: {
	enabled?: null | bool @go(Enabled,*bool)
}

#NodePoolNodeConfigGvnicObservation: {
	enabled?: null | bool @go(Enabled,*bool)
}

#NodePoolNodeConfigGvnicParameters: {
	// +kubebuilder:validation:Optional
	enabled?: null | bool @go(Enabled,*bool)
}

#NodePoolNodeConfigHostMaintenancePolicyInitParameters: {
	maintenanceInterval?: null | string @go(MaintenanceInterval,*string)
}

#NodePoolNodeConfigHostMaintenancePolicyObservation: {
	maintenanceInterval?: null | string @go(MaintenanceInterval,*string)
}

#NodePoolNodeConfigHostMaintenancePolicyParameters: {
	// +kubebuilder:validation:Optional
	maintenanceInterval?: null | string @go(MaintenanceInterval,*string)
}

#NodePoolNodeConfigInitParameters_2: {
	advancedMachineFeatures?: [...#NodePoolNodeConfigAdvancedMachineFeaturesInitParameters] @go(AdvancedMachineFeatures,[]NodePoolNodeConfigAdvancedMachineFeaturesInitParameters)
	bootDiskKmsKey?: null | string  @go(BootDiskKMSKey,*string)
	diskSizeGb?:     null | float64 @go(DiskSizeGb,*float64)
	diskType?:       null | string  @go(DiskType,*string)
	ephemeralStorageLocalSsdConfig?: [...#NodePoolNodeConfigEphemeralStorageLocalSsdConfigInitParameters] @go(EphemeralStorageLocalSsdConfig,[]NodePoolNodeConfigEphemeralStorageLocalSsdConfigInitParameters)
	gcfsConfig?: [...#NodePoolNodeConfigGcfsConfigInitParameters] @go(GcfsConfig,[]NodePoolNodeConfigGcfsConfigInitParameters)
	guestAccelerator?: [...#NodePoolNodeConfigGuestAcceleratorInitParameters] @go(GuestAccelerator,[]NodePoolNodeConfigGuestAcceleratorInitParameters)
	gvnic?: [...#NodePoolNodeConfigGvnicInitParameters] @go(Gvnic,[]NodePoolNodeConfigGvnicInitParameters)
	hostMaintenancePolicy?: [...#NodePoolNodeConfigHostMaintenancePolicyInitParameters] @go(HostMaintenancePolicy,[]NodePoolNodeConfigHostMaintenancePolicyInitParameters)
	imageType?: null | string @go(ImageType,*string)
	kubeletConfig?: [...#NodePoolNodeConfigKubeletConfigInitParameters] @go(KubeletConfig,[]NodePoolNodeConfigKubeletConfigInitParameters)
	labels?: {[string]: null | string} @go(Labels,map[string]*string)

	// Parameters used in creating the node pool. See
	// google_container_cluster for schema.
	linuxNodeConfig?: [...#NodePoolNodeConfigLinuxNodeConfigInitParameters] @go(LinuxNodeConfig,[]NodePoolNodeConfigLinuxNodeConfigInitParameters)
	localNvmeSsdBlockConfig?: [...#NodePoolNodeConfigLocalNvmeSsdBlockConfigInitParameters] @go(LocalNvmeSsdBlockConfig,[]NodePoolNodeConfigLocalNvmeSsdBlockConfigInitParameters)
	localSsdCount?:  null | float64 @go(LocalSsdCount,*float64)
	loggingVariant?: null | string  @go(LoggingVariant,*string)
	machineType?:    null | string  @go(MachineType,*string)
	metadata?: {[string]: null | string} @go(Metadata,map[string]*string)
	minCpuPlatform?: null | string @go(MinCPUPlatform,*string)
	nodeGroup?:      null | string @go(NodeGroup,*string)
	oauthScopes?: [...null | string] @go(OAuthScopes,[]*string)
	preemptible?: null | bool @go(Preemptible,*bool)
	reservationAffinity?: [...#NodePoolNodeConfigReservationAffinityInitParameters] @go(ReservationAffinity,[]NodePoolNodeConfigReservationAffinityInitParameters)
	resourceLabels?: {[string]: null | string} @go(ResourceLabels,map[string]*string)
	shieldedInstanceConfig?: [...#NodePoolNodeConfigShieldedInstanceConfigInitParameters_2] @go(ShieldedInstanceConfig,[]NodePoolNodeConfigShieldedInstanceConfigInitParameters_2)
	soleTenantConfig?: [...#NodePoolNodeConfigSoleTenantConfigInitParameters] @go(SoleTenantConfig,[]NodePoolNodeConfigSoleTenantConfigInitParameters)
	spot?: null | bool @go(Spot,*bool)
	tags?: [...null | string] @go(Tags,[]*string)
	taint?: [...#NodePoolNodeConfigTaintInitParameters] @go(Taint,[]NodePoolNodeConfigTaintInitParameters)
	workloadMetadataConfig?: [...#NodePoolNodeConfigWorkloadMetadataConfigInitParameters] @go(WorkloadMetadataConfig,[]NodePoolNodeConfigWorkloadMetadataConfigInitParameters)
}

#NodePoolNodeConfigKubeletConfigInitParameters: {
	cpuCfsQuota?:       null | bool    @go(CPUCfsQuota,*bool)
	cpuCfsQuotaPeriod?: null | string  @go(CPUCfsQuotaPeriod,*string)
	cpuManagerPolicy?:  null | string  @go(CPUManagerPolicy,*string)
	podPidsLimit?:      null | float64 @go(PodPidsLimit,*float64)
}

#NodePoolNodeConfigKubeletConfigObservation: {
	cpuCfsQuota?:       null | bool    @go(CPUCfsQuota,*bool)
	cpuCfsQuotaPeriod?: null | string  @go(CPUCfsQuotaPeriod,*string)
	cpuManagerPolicy?:  null | string  @go(CPUManagerPolicy,*string)
	podPidsLimit?:      null | float64 @go(PodPidsLimit,*float64)
}

#NodePoolNodeConfigKubeletConfigParameters: {
	// +kubebuilder:validation:Optional
	cpuCfsQuota?: null | bool @go(CPUCfsQuota,*bool)

	// +kubebuilder:validation:Optional
	cpuCfsQuotaPeriod?: null | string @go(CPUCfsQuotaPeriod,*string)

	// +kubebuilder:validation:Optional
	cpuManagerPolicy?: null | string @go(CPUManagerPolicy,*string)

	// +kubebuilder:validation:Optional
	podPidsLimit?: null | float64 @go(PodPidsLimit,*float64)
}

#NodePoolNodeConfigLinuxNodeConfigInitParameters: {
	sysctls?: {[string]: null | string} @go(Sysctls,map[string]*string)
}

#NodePoolNodeConfigLinuxNodeConfigObservation: {
	sysctls?: {[string]: null | string} @go(Sysctls,map[string]*string)
}

#NodePoolNodeConfigLinuxNodeConfigParameters: {
	// +kubebuilder:validation:Optional
	sysctls: {[string]: null | string} @go(Sysctls,map[string]*string)
}

#NodePoolNodeConfigLocalNvmeSsdBlockConfigInitParameters: {
	localSsdCount?: null | float64 @go(LocalSsdCount,*float64)
}

#NodePoolNodeConfigLocalNvmeSsdBlockConfigObservation: {
	localSsdCount?: null | float64 @go(LocalSsdCount,*float64)
}

#NodePoolNodeConfigLocalNvmeSsdBlockConfigParameters: {
	// +kubebuilder:validation:Optional
	localSsdCount?: null | float64 @go(LocalSsdCount,*float64)
}

#NodePoolNodeConfigObservation_2: {
	advancedMachineFeatures?: [...#NodePoolNodeConfigAdvancedMachineFeaturesObservation] @go(AdvancedMachineFeatures,[]NodePoolNodeConfigAdvancedMachineFeaturesObservation)
	bootDiskKmsKey?: null | string  @go(BootDiskKMSKey,*string)
	diskSizeGb?:     null | float64 @go(DiskSizeGb,*float64)
	diskType?:       null | string  @go(DiskType,*string)
	ephemeralStorageLocalSsdConfig?: [...#NodePoolNodeConfigEphemeralStorageLocalSsdConfigObservation] @go(EphemeralStorageLocalSsdConfig,[]NodePoolNodeConfigEphemeralStorageLocalSsdConfigObservation)
	gcfsConfig?: [...#NodePoolNodeConfigGcfsConfigObservation] @go(GcfsConfig,[]NodePoolNodeConfigGcfsConfigObservation)
	guestAccelerator?: [...#NodePoolNodeConfigGuestAcceleratorObservation] @go(GuestAccelerator,[]NodePoolNodeConfigGuestAcceleratorObservation)
	gvnic?: [...#NodePoolNodeConfigGvnicObservation] @go(Gvnic,[]NodePoolNodeConfigGvnicObservation)
	hostMaintenancePolicy?: [...#NodePoolNodeConfigHostMaintenancePolicyObservation] @go(HostMaintenancePolicy,[]NodePoolNodeConfigHostMaintenancePolicyObservation)
	imageType?: null | string @go(ImageType,*string)
	kubeletConfig?: [...#NodePoolNodeConfigKubeletConfigObservation] @go(KubeletConfig,[]NodePoolNodeConfigKubeletConfigObservation)
	labels?: {[string]: null | string} @go(Labels,map[string]*string)

	// Parameters used in creating the node pool. See
	// google_container_cluster for schema.
	linuxNodeConfig?: [...#NodePoolNodeConfigLinuxNodeConfigObservation] @go(LinuxNodeConfig,[]NodePoolNodeConfigLinuxNodeConfigObservation)
	localNvmeSsdBlockConfig?: [...#NodePoolNodeConfigLocalNvmeSsdBlockConfigObservation] @go(LocalNvmeSsdBlockConfig,[]NodePoolNodeConfigLocalNvmeSsdBlockConfigObservation)
	localSsdCount?:  null | float64 @go(LocalSsdCount,*float64)
	loggingVariant?: null | string  @go(LoggingVariant,*string)
	machineType?:    null | string  @go(MachineType,*string)
	metadata?: {[string]: null | string} @go(Metadata,map[string]*string)
	minCpuPlatform?: null | string @go(MinCPUPlatform,*string)
	nodeGroup?:      null | string @go(NodeGroup,*string)
	oauthScopes?: [...null | string] @go(OAuthScopes,[]*string)
	preemptible?: null | bool @go(Preemptible,*bool)
	reservationAffinity?: [...#NodePoolNodeConfigReservationAffinityObservation] @go(ReservationAffinity,[]NodePoolNodeConfigReservationAffinityObservation)
	resourceLabels?: {[string]: null | string} @go(ResourceLabels,map[string]*string)
	serviceAccount?: null | string @go(ServiceAccount,*string)
	shieldedInstanceConfig?: [...#NodePoolNodeConfigShieldedInstanceConfigObservation_2] @go(ShieldedInstanceConfig,[]NodePoolNodeConfigShieldedInstanceConfigObservation_2)
	soleTenantConfig?: [...#NodePoolNodeConfigSoleTenantConfigObservation] @go(SoleTenantConfig,[]NodePoolNodeConfigSoleTenantConfigObservation)
	spot?: null | bool @go(Spot,*bool)
	tags?: [...null | string] @go(Tags,[]*string)
	taint?: [...#NodePoolNodeConfigTaintObservation] @go(Taint,[]NodePoolNodeConfigTaintObservation)
	workloadMetadataConfig?: [...#NodePoolNodeConfigWorkloadMetadataConfigObservation] @go(WorkloadMetadataConfig,[]NodePoolNodeConfigWorkloadMetadataConfigObservation)
}

#NodePoolNodeConfigParameters_2: {
	// +kubebuilder:validation:Optional
	advancedMachineFeatures?: [...#NodePoolNodeConfigAdvancedMachineFeaturesParameters] @go(AdvancedMachineFeatures,[]NodePoolNodeConfigAdvancedMachineFeaturesParameters)

	// +kubebuilder:validation:Optional
	bootDiskKmsKey?: null | string @go(BootDiskKMSKey,*string)

	// +kubebuilder:validation:Optional
	diskSizeGb?: null | float64 @go(DiskSizeGb,*float64)

	// +kubebuilder:validation:Optional
	diskType?: null | string @go(DiskType,*string)

	// +kubebuilder:validation:Optional
	ephemeralStorageLocalSsdConfig?: [...#NodePoolNodeConfigEphemeralStorageLocalSsdConfigParameters] @go(EphemeralStorageLocalSsdConfig,[]NodePoolNodeConfigEphemeralStorageLocalSsdConfigParameters)

	// +kubebuilder:validation:Optional
	gcfsConfig?: [...#NodePoolNodeConfigGcfsConfigParameters] @go(GcfsConfig,[]NodePoolNodeConfigGcfsConfigParameters)

	// +kubebuilder:validation:Optional
	guestAccelerator?: [...#NodePoolNodeConfigGuestAcceleratorParameters] @go(GuestAccelerator,[]NodePoolNodeConfigGuestAcceleratorParameters)

	// +kubebuilder:validation:Optional
	gvnic?: [...#NodePoolNodeConfigGvnicParameters] @go(Gvnic,[]NodePoolNodeConfigGvnicParameters)

	// +kubebuilder:validation:Optional
	hostMaintenancePolicy?: [...#NodePoolNodeConfigHostMaintenancePolicyParameters] @go(HostMaintenancePolicy,[]NodePoolNodeConfigHostMaintenancePolicyParameters)

	// +kubebuilder:validation:Optional
	imageType?: null | string @go(ImageType,*string)

	// +kubebuilder:validation:Optional
	kubeletConfig?: [...#NodePoolNodeConfigKubeletConfigParameters] @go(KubeletConfig,[]NodePoolNodeConfigKubeletConfigParameters)

	// +kubebuilder:validation:Optional
	labels?: {[string]: null | string} @go(Labels,map[string]*string)

	// Parameters used in creating the node pool. See
	// google_container_cluster for schema.
	// +kubebuilder:validation:Optional
	linuxNodeConfig?: [...#NodePoolNodeConfigLinuxNodeConfigParameters] @go(LinuxNodeConfig,[]NodePoolNodeConfigLinuxNodeConfigParameters)

	// +kubebuilder:validation:Optional
	localNvmeSsdBlockConfig?: [...#NodePoolNodeConfigLocalNvmeSsdBlockConfigParameters] @go(LocalNvmeSsdBlockConfig,[]NodePoolNodeConfigLocalNvmeSsdBlockConfigParameters)

	// +kubebuilder:validation:Optional
	localSsdCount?: null | float64 @go(LocalSsdCount,*float64)

	// +kubebuilder:validation:Optional
	loggingVariant?: null | string @go(LoggingVariant,*string)

	// +kubebuilder:validation:Optional
	machineType?: null | string @go(MachineType,*string)

	// +kubebuilder:validation:Optional
	metadata?: {[string]: null | string} @go(Metadata,map[string]*string)

	// +kubebuilder:validation:Optional
	minCpuPlatform?: null | string @go(MinCPUPlatform,*string)

	// +kubebuilder:validation:Optional
	nodeGroup?: null | string @go(NodeGroup,*string)

	// +kubebuilder:validation:Optional
	oauthScopes?: [...null | string] @go(OAuthScopes,[]*string)

	// +kubebuilder:validation:Optional
	preemptible?: null | bool @go(Preemptible,*bool)

	// +kubebuilder:validation:Optional
	reservationAffinity?: [...#NodePoolNodeConfigReservationAffinityParameters] @go(ReservationAffinity,[]NodePoolNodeConfigReservationAffinityParameters)

	// +kubebuilder:validation:Optional
	resourceLabels?: {[string]: null | string} @go(ResourceLabels,map[string]*string)

	// +crossplane:generate:reference:type=github.com/upbound/provider-gcp/apis/cloudplatform/v1beta1.ServiceAccount
	// +crossplane:generate:reference:extractor=github.com/upbound/upjet/pkg/resource.ExtractParamPath("email",true)
	// +kubebuilder:validation:Optional
	serviceAccount?: null | string @go(ServiceAccount,*string)

	// Reference to a ServiceAccount in cloudplatform to populate serviceAccount.
	// +kubebuilder:validation:Optional
	serviceAccountRef?: null | v1.#Reference @go(ServiceAccountRef,*v1.Reference)

	// Selector for a ServiceAccount in cloudplatform to populate serviceAccount.
	// +kubebuilder:validation:Optional
	serviceAccountSelector?: null | v1.#Selector @go(ServiceAccountSelector,*v1.Selector)

	// +kubebuilder:validation:Optional
	shieldedInstanceConfig?: [...#NodePoolNodeConfigShieldedInstanceConfigParameters_2] @go(ShieldedInstanceConfig,[]NodePoolNodeConfigShieldedInstanceConfigParameters_2)

	// +kubebuilder:validation:Optional
	soleTenantConfig?: [...#NodePoolNodeConfigSoleTenantConfigParameters] @go(SoleTenantConfig,[]NodePoolNodeConfigSoleTenantConfigParameters)

	// +kubebuilder:validation:Optional
	spot?: null | bool @go(Spot,*bool)

	// +kubebuilder:validation:Optional
	tags?: [...null | string] @go(Tags,[]*string)

	// +kubebuilder:validation:Optional
	taint?: [...#NodePoolNodeConfigTaintParameters] @go(Taint,[]NodePoolNodeConfigTaintParameters)

	// +kubebuilder:validation:Optional
	workloadMetadataConfig?: [...#NodePoolNodeConfigWorkloadMetadataConfigParameters] @go(WorkloadMetadataConfig,[]NodePoolNodeConfigWorkloadMetadataConfigParameters)
}

#NodePoolNodeConfigReservationAffinityInitParameters: {
	consumeReservationType?: null | string @go(ConsumeReservationType,*string)
	key?:                    null | string @go(Key,*string)
	values?: [...null | string] @go(Values,[]*string)
}

#NodePoolNodeConfigReservationAffinityObservation: {
	consumeReservationType?: null | string @go(ConsumeReservationType,*string)
	key?:                    null | string @go(Key,*string)
	values?: [...null | string] @go(Values,[]*string)
}

#NodePoolNodeConfigReservationAffinityParameters: {
	// +kubebuilder:validation:Optional
	consumeReservationType?: null | string @go(ConsumeReservationType,*string)

	// +kubebuilder:validation:Optional
	key?: null | string @go(Key,*string)

	// +kubebuilder:validation:Optional
	values?: [...null | string] @go(Values,[]*string)
}

#NodePoolNodeConfigShieldedInstanceConfigInitParameters_2: {
	enableIntegrityMonitoring?: null | bool @go(EnableIntegrityMonitoring,*bool)
	enableSecureBoot?:          null | bool @go(EnableSecureBoot,*bool)
}

#NodePoolNodeConfigShieldedInstanceConfigObservation_2: {
	enableIntegrityMonitoring?: null | bool @go(EnableIntegrityMonitoring,*bool)
	enableSecureBoot?:          null | bool @go(EnableSecureBoot,*bool)
}

#NodePoolNodeConfigShieldedInstanceConfigParameters_2: {
	// +kubebuilder:validation:Optional
	enableIntegrityMonitoring?: null | bool @go(EnableIntegrityMonitoring,*bool)

	// +kubebuilder:validation:Optional
	enableSecureBoot?: null | bool @go(EnableSecureBoot,*bool)
}

#NodePoolNodeConfigSoleTenantConfigInitParameters: {
	nodeAffinity?: [...#NodeConfigSoleTenantConfigNodeAffinityInitParameters] @go(NodeAffinity,[]NodeConfigSoleTenantConfigNodeAffinityInitParameters)
}

#NodePoolNodeConfigSoleTenantConfigObservation: {
	nodeAffinity?: [...#NodeConfigSoleTenantConfigNodeAffinityObservation] @go(NodeAffinity,[]NodeConfigSoleTenantConfigNodeAffinityObservation)
}

#NodePoolNodeConfigSoleTenantConfigParameters: {
	// +kubebuilder:validation:Optional
	nodeAffinity: [...#NodeConfigSoleTenantConfigNodeAffinityParameters] @go(NodeAffinity,[]NodeConfigSoleTenantConfigNodeAffinityParameters)
}

#NodePoolNodeConfigTaintInitParameters: {
	effect?: null | string @go(Effect,*string)
	key?:    null | string @go(Key,*string)
	value?:  null | string @go(Value,*string)
}

#NodePoolNodeConfigTaintObservation: {
	effect?: null | string @go(Effect,*string)
	key?:    null | string @go(Key,*string)
	value?:  null | string @go(Value,*string)
}

#NodePoolNodeConfigTaintParameters: {
	// +kubebuilder:validation:Optional
	effect?: null | string @go(Effect,*string)

	// +kubebuilder:validation:Optional
	key?: null | string @go(Key,*string)

	// +kubebuilder:validation:Optional
	value?: null | string @go(Value,*string)
}

#NodePoolNodeConfigWorkloadMetadataConfigInitParameters: {
	mode?: null | string @go(Mode,*string)
}

#NodePoolNodeConfigWorkloadMetadataConfigObservation: {
	mode?: null | string @go(Mode,*string)
}

#NodePoolNodeConfigWorkloadMetadataConfigParameters: {
	// +kubebuilder:validation:Optional
	mode?: null | string @go(Mode,*string)
}

#NodePoolObservation_2: {
	// Configuration required by cluster autoscaler to adjust
	// the size of the node pool to the current cluster usage. Structure is documented below.
	autoscaling?: [...#NodePoolAutoscalingObservation] @go(Autoscaling,[]NodePoolAutoscalingObservation)

	// The cluster to create the node pool for. Cluster must be present in location provided for clusters. May be specified in the format projects/{{project}}/locations/{{location}}/clusters/{{cluster}} or as just the name of the cluster.
	cluster?: null | string @go(Cluster,*string)

	// an identifier for the resource with format {{project}}/{{location}}/{{cluster}}/{{name}}
	id?: null | string @go(ID,*string)

	// The initial number of nodes for the pool. In
	// regional or multi-zonal clusters, this is the number of nodes per zone. Changing
	// this will force recreation of the resource.  If you don't
	// need this value, don't set it.  If you do need it, you can use a lifecycle block to
	// ignore subsequent changes to this field.
	initialNodeCount?: null | float64 @go(InitialNodeCount,*float64)

	// The resource URLs of the managed instance groups associated with this node pool.
	instanceGroupUrls?: [...null | string] @go(InstanceGroupUrls,[]*string)

	// The location (region or zone) of the cluster.
	location?: null | string @go(Location,*string)

	// List of instance group URLs which have been assigned to this node pool.
	managedInstanceGroupUrls?: [...null | string] @go(ManagedInstanceGroupUrls,[]*string)

	// Node management configuration, wherein auto-repair and
	// auto-upgrade is configured. Structure is documented below.
	management?: [...#NodePoolManagementObservation_2] @go(Management,[]NodePoolManagementObservation_2)

	// The maximum number of pods per node in this node pool.
	// Note that this does not work on node pools which are "route-based" - that is, node
	// pools belonging to clusters that do not have IP Aliasing enabled.
	// See the official documentation
	// for more information.
	maxPodsPerNode?: null | float64 @go(MaxPodsPerNode,*float64)

	// The network configuration of the pool. Such as
	// configuration for Adding Pod IP address ranges) to the node pool. Or enabling private nodes. Structure is
	// documented below
	networkConfig?: [...#NodePoolNetworkConfigObservation] @go(NetworkConfig,[]NodePoolNetworkConfigObservation)

	// Parameters used in creating the node pool. See
	// google_container_cluster for schema.
	nodeConfig?: [...#NodePoolNodeConfigObservation_2] @go(NodeConfig,[]NodePoolNodeConfigObservation_2)

	// The number of nodes per instance group. This field can be used to
	// update the number of nodes per instance group but should not be used alongside autoscaling.
	nodeCount?: null | float64 @go(NodeCount,*float64)

	// The list of zones in which the node pool's nodes should be located. Nodes must
	// be in the region of their regional cluster or in the same region as their
	// cluster's zone for zonal clusters. If unspecified, the cluster-level
	// node_locations will be used.
	nodeLocations?: [...null | string] @go(NodeLocations,[]*string)
	operation?: null | string @go(Operation,*string)

	// Specifies a custom placement policy for the
	// nodes.
	placementPolicy?: [...#NodePoolPlacementPolicyObservation] @go(PlacementPolicy,[]NodePoolPlacementPolicyObservation)

	// The ID of the project in which to create the node pool. If blank,
	// the provider-configured project will be used.
	project?: null | string @go(Project,*string)

	// Specify node upgrade settings to change how GKE upgrades nodes.
	// The maximum number of nodes upgraded simultaneously is limited to 20. Structure is documented below.
	upgradeSettings?: [...#NodePoolUpgradeSettingsObservation_2] @go(UpgradeSettings,[]NodePoolUpgradeSettingsObservation_2)

	// The Kubernetes version for the nodes in this pool. Note that if this field
	// and auto_upgrade are both specified, they will fight each other for what the node version should
	// be, so setting both is highly discouraged.
	version?: null | string @go(Version,*string)
}

#NodePoolParameters_2: {
	// Configuration required by cluster autoscaler to adjust
	// the size of the node pool to the current cluster usage. Structure is documented below.
	// +kubebuilder:validation:Optional
	autoscaling?: [...#NodePoolAutoscalingParameters] @go(Autoscaling,[]NodePoolAutoscalingParameters)

	// The cluster to create the node pool for. Cluster must be present in location provided for clusters. May be specified in the format projects/{{project}}/locations/{{location}}/clusters/{{cluster}} or as just the name of the cluster.
	// +crossplane:generate:reference:type=Cluster
	// +crossplane:generate:reference:extractor=github.com/upbound/provider-gcp/config/common.ExtractResourceID()
	// +kubebuilder:validation:Optional
	cluster?: null | string @go(Cluster,*string)

	// Reference to a Cluster to populate cluster.
	// +kubebuilder:validation:Optional
	clusterRef?: null | v1.#Reference @go(ClusterRef,*v1.Reference)

	// Selector for a Cluster to populate cluster.
	// +kubebuilder:validation:Optional
	clusterSelector?: null | v1.#Selector @go(ClusterSelector,*v1.Selector)

	// The initial number of nodes for the pool. In
	// regional or multi-zonal clusters, this is the number of nodes per zone. Changing
	// this will force recreation of the resource.  If you don't
	// need this value, don't set it.  If you do need it, you can use a lifecycle block to
	// ignore subsequent changes to this field.
	// +kubebuilder:validation:Optional
	initialNodeCount?: null | float64 @go(InitialNodeCount,*float64)

	// The location (region or zone) of the cluster.
	// +kubebuilder:validation:Optional
	location?: null | string @go(Location,*string)

	// Node management configuration, wherein auto-repair and
	// auto-upgrade is configured. Structure is documented below.
	// +kubebuilder:validation:Optional
	management?: [...#NodePoolManagementParameters_2] @go(Management,[]NodePoolManagementParameters_2)

	// The maximum number of pods per node in this node pool.
	// Note that this does not work on node pools which are "route-based" - that is, node
	// pools belonging to clusters that do not have IP Aliasing enabled.
	// See the official documentation
	// for more information.
	// +kubebuilder:validation:Optional
	maxPodsPerNode?: null | float64 @go(MaxPodsPerNode,*float64)

	// The network configuration of the pool. Such as
	// configuration for Adding Pod IP address ranges) to the node pool. Or enabling private nodes. Structure is
	// documented below
	// +kubebuilder:validation:Optional
	networkConfig?: [...#NodePoolNetworkConfigParameters] @go(NetworkConfig,[]NodePoolNetworkConfigParameters)

	// Parameters used in creating the node pool. See
	// google_container_cluster for schema.
	// +kubebuilder:validation:Optional
	nodeConfig?: [...#NodePoolNodeConfigParameters_2] @go(NodeConfig,[]NodePoolNodeConfigParameters_2)

	// The number of nodes per instance group. This field can be used to
	// update the number of nodes per instance group but should not be used alongside autoscaling.
	// +kubebuilder:validation:Optional
	nodeCount?: null | float64 @go(NodeCount,*float64)

	// The list of zones in which the node pool's nodes should be located. Nodes must
	// be in the region of their regional cluster or in the same region as their
	// cluster's zone for zonal clusters. If unspecified, the cluster-level
	// node_locations will be used.
	// +kubebuilder:validation:Optional
	nodeLocations?: [...null | string] @go(NodeLocations,[]*string)

	// Specifies a custom placement policy for the
	// nodes.
	// +kubebuilder:validation:Optional
	placementPolicy?: [...#NodePoolPlacementPolicyParameters] @go(PlacementPolicy,[]NodePoolPlacementPolicyParameters)

	// The ID of the project in which to create the node pool. If blank,
	// the provider-configured project will be used.
	// +kubebuilder:validation:Optional
	project?: null | string @go(Project,*string)

	// Specify node upgrade settings to change how GKE upgrades nodes.
	// The maximum number of nodes upgraded simultaneously is limited to 20. Structure is documented below.
	// +kubebuilder:validation:Optional
	upgradeSettings?: [...#NodePoolUpgradeSettingsParameters_2] @go(UpgradeSettings,[]NodePoolUpgradeSettingsParameters_2)

	// The Kubernetes version for the nodes in this pool. Note that if this field
	// and auto_upgrade are both specified, they will fight each other for what the node version should
	// be, so setting both is highly discouraged.
	// +kubebuilder:validation:Optional
	version?: null | string @go(Version,*string)
}

#NodePoolPlacementPolicyInitParameters: {
	// If set, refers to the name of a custom resource policy supplied by the user.
	// The resource policy must be in the same project and region as the node pool.
	// If not found, InvalidArgument error is returned.
	policyName?: null | string @go(PolicyName,*string)

	// The type of the policy. Supports a single value: COMPACT.
	// Specifying COMPACT placement policy type places node pool's nodes in a closer
	// physical proximity in order to reduce network latency between nodes.
	type?: null | string @go(Type,*string)
}

#NodePoolPlacementPolicyObservation: {
	// If set, refers to the name of a custom resource policy supplied by the user.
	// The resource policy must be in the same project and region as the node pool.
	// If not found, InvalidArgument error is returned.
	policyName?: null | string @go(PolicyName,*string)

	// The type of the policy. Supports a single value: COMPACT.
	// Specifying COMPACT placement policy type places node pool's nodes in a closer
	// physical proximity in order to reduce network latency between nodes.
	type?: null | string @go(Type,*string)
}

#NodePoolPlacementPolicyParameters: {
	// If set, refers to the name of a custom resource policy supplied by the user.
	// The resource policy must be in the same project and region as the node pool.
	// If not found, InvalidArgument error is returned.
	// +kubebuilder:validation:Optional
	policyName?: null | string @go(PolicyName,*string)

	// The type of the policy. Supports a single value: COMPACT.
	// Specifying COMPACT placement policy type places node pool's nodes in a closer
	// physical proximity in order to reduce network latency between nodes.
	// +kubebuilder:validation:Optional
	type?: null | string @go(Type,*string)
}

#NodePoolUpgradeSettingsBlueGreenSettingsInitParameters: {
	// Time needed after draining the entire blue pool.
	// After this period, the blue pool will be cleaned up.
	nodePoolSoakDuration?: null | string @go(NodePoolSoakDuration,*string)

	// Specifies the standard policy settings for blue-green upgrades.
	standardRolloutPolicy?: [...#UpgradeSettingsBlueGreenSettingsStandardRolloutPolicyInitParameters] @go(StandardRolloutPolicy,[]UpgradeSettingsBlueGreenSettingsStandardRolloutPolicyInitParameters)
}

#NodePoolUpgradeSettingsBlueGreenSettingsObservation: {
	// Time needed after draining the entire blue pool.
	// After this period, the blue pool will be cleaned up.
	nodePoolSoakDuration?: null | string @go(NodePoolSoakDuration,*string)

	// Specifies the standard policy settings for blue-green upgrades.
	standardRolloutPolicy?: [...#UpgradeSettingsBlueGreenSettingsStandardRolloutPolicyObservation] @go(StandardRolloutPolicy,[]UpgradeSettingsBlueGreenSettingsStandardRolloutPolicyObservation)
}

#NodePoolUpgradeSettingsBlueGreenSettingsParameters: {
	// Time needed after draining the entire blue pool.
	// After this period, the blue pool will be cleaned up.
	// +kubebuilder:validation:Optional
	nodePoolSoakDuration?: null | string @go(NodePoolSoakDuration,*string)

	// Specifies the standard policy settings for blue-green upgrades.
	// +kubebuilder:validation:Optional
	standardRolloutPolicy: [...#UpgradeSettingsBlueGreenSettingsStandardRolloutPolicyParameters] @go(StandardRolloutPolicy,[]UpgradeSettingsBlueGreenSettingsStandardRolloutPolicyParameters)
}

#NodePoolUpgradeSettingsInitParameters_2: {
	// The settings to adjust blue green upgrades.
	// Structure is documented below
	blueGreenSettings?: [...#NodePoolUpgradeSettingsBlueGreenSettingsInitParameters] @go(BlueGreenSettings,[]NodePoolUpgradeSettingsBlueGreenSettingsInitParameters)

	// The number of additional nodes that can be added to the node pool during
	// an upgrade. Increasing max_surge raises the number of nodes that can be upgraded simultaneously.
	// Can be set to 0 or greater.
	maxSurge?: null | float64 @go(MaxSurge,*float64)

	// The number of nodes that can be simultaneously unavailable during
	// an upgrade. Increasing max_unavailable raises the number of nodes that can be upgraded in
	// parallel. Can be set to 0 or greater.
	maxUnavailable?: null | float64 @go(MaxUnavailable,*float64)

	// (Default SURGE) The upgrade stragey to be used for upgrading the nodes.
	strategy?: null | string @go(Strategy,*string)
}

#NodePoolUpgradeSettingsObservation_2: {
	// The settings to adjust blue green upgrades.
	// Structure is documented below
	blueGreenSettings?: [...#NodePoolUpgradeSettingsBlueGreenSettingsObservation] @go(BlueGreenSettings,[]NodePoolUpgradeSettingsBlueGreenSettingsObservation)

	// The number of additional nodes that can be added to the node pool during
	// an upgrade. Increasing max_surge raises the number of nodes that can be upgraded simultaneously.
	// Can be set to 0 or greater.
	maxSurge?: null | float64 @go(MaxSurge,*float64)

	// The number of nodes that can be simultaneously unavailable during
	// an upgrade. Increasing max_unavailable raises the number of nodes that can be upgraded in
	// parallel. Can be set to 0 or greater.
	maxUnavailable?: null | float64 @go(MaxUnavailable,*float64)

	// (Default SURGE) The upgrade stragey to be used for upgrading the nodes.
	strategy?: null | string @go(Strategy,*string)
}

#NodePoolUpgradeSettingsParameters_2: {
	// The settings to adjust blue green upgrades.
	// Structure is documented below
	// +kubebuilder:validation:Optional
	blueGreenSettings?: [...#NodePoolUpgradeSettingsBlueGreenSettingsParameters] @go(BlueGreenSettings,[]NodePoolUpgradeSettingsBlueGreenSettingsParameters)

	// The number of additional nodes that can be added to the node pool during
	// an upgrade. Increasing max_surge raises the number of nodes that can be upgraded simultaneously.
	// Can be set to 0 or greater.
	// +kubebuilder:validation:Optional
	maxSurge?: null | float64 @go(MaxSurge,*float64)

	// The number of nodes that can be simultaneously unavailable during
	// an upgrade. Increasing max_unavailable raises the number of nodes that can be upgraded in
	// parallel. Can be set to 0 or greater.
	// +kubebuilder:validation:Optional
	maxUnavailable?: null | float64 @go(MaxUnavailable,*float64)

	// (Default SURGE) The upgrade stragey to be used for upgrading the nodes.
	// +kubebuilder:validation:Optional
	strategy?: null | string @go(Strategy,*string)
}

#UpgradeSettingsBlueGreenSettingsStandardRolloutPolicyInitParameters: {
	// Number of blue nodes to drain in a batch.
	batchNodeCount?: null | float64 @go(BatchNodeCount,*float64)

	// Percentage of the blue pool nodes to drain in a batch.
	batchPercentage?: null | float64 @go(BatchPercentage,*float64)

	// (Optionial) Soak time after each batch gets drained.
	batchSoakDuration?: null | string @go(BatchSoakDuration,*string)
}

#UpgradeSettingsBlueGreenSettingsStandardRolloutPolicyObservation: {
	// Number of blue nodes to drain in a batch.
	batchNodeCount?: null | float64 @go(BatchNodeCount,*float64)

	// Percentage of the blue pool nodes to drain in a batch.
	batchPercentage?: null | float64 @go(BatchPercentage,*float64)

	// (Optionial) Soak time after each batch gets drained.
	batchSoakDuration?: null | string @go(BatchSoakDuration,*string)
}

#UpgradeSettingsBlueGreenSettingsStandardRolloutPolicyParameters: {
	// Number of blue nodes to drain in a batch.
	// +kubebuilder:validation:Optional
	batchNodeCount?: null | float64 @go(BatchNodeCount,*float64)

	// Percentage of the blue pool nodes to drain in a batch.
	// +kubebuilder:validation:Optional
	batchPercentage?: null | float64 @go(BatchPercentage,*float64)

	// (Optionial) Soak time after each batch gets drained.
	// +kubebuilder:validation:Optional
	batchSoakDuration?: null | string @go(BatchSoakDuration,*string)
}

// NodePoolSpec defines the desired state of NodePool
#NodePoolSpec: {
	v1.#ResourceSpec
	forProvider: #NodePoolParameters_2 @go(ForProvider)

	// THIS IS AN ALPHA FIELD. Do not use it in production. It is not honored
	// unless the relevant Crossplane feature flag is enabled, and may be
	// changed or removed without notice.
	// InitProvider holds the same fields as ForProvider, with the exception
	// of Identifier and other resource reference fields. The fields that are
	// in InitProvider are merged into ForProvider when the resource is created.
	// The same fields are also added to the terraform ignore_changes hook, to
	// avoid updating them after creation. This is useful for fields that are
	// required on creation, but we do not desire to update them after creation,
	// for example because of an external controller is managing them, like an
	// autoscaler.
	initProvider?: #NodePoolInitParameters_2 @go(InitProvider)
}

// NodePoolStatus defines the observed state of NodePool.
#NodePoolStatus: {
	v1.#ResourceStatus
	atProvider?: #NodePoolObservation_2 @go(AtProvider)
}

// NodePool is the Schema for the NodePools API. Manages a GKE NodePool resource.
// +kubebuilder:printcolumn:name="READY",type="string",JSONPath=".status.conditions[?(@.type=='Ready')].status"
// +kubebuilder:printcolumn:name="SYNCED",type="string",JSONPath=".status.conditions[?(@.type=='Synced')].status"
// +kubebuilder:printcolumn:name="EXTERNAL-NAME",type="string",JSONPath=".metadata.annotations.crossplane\\.io/external-name"
// +kubebuilder:printcolumn:name="AGE",type="date",JSONPath=".metadata.creationTimestamp"
// +kubebuilder:subresource:status
// +kubebuilder:resource:scope=Cluster,categories={crossplane,managed,gcp}
#NodePool: {
	metav1.#TypeMeta
	metadata?: metav1.#ObjectMeta @go(ObjectMeta)
	spec:      #NodePoolSpec      @go(Spec)
	status?:   #NodePoolStatus    @go(Status)
}

// NodePoolList contains a list of NodePools
#NodePoolList: {
	metav1.#TypeMeta
	metadata?: metav1.#ListMeta @go(ListMeta)
	items: [...#NodePool] @go(Items,[]NodePool)
}
